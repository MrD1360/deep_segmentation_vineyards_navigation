{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vineyards navigation with semantic segmentation\n",
    "\n",
    "Using semantic segmentation for a proportional controller along the vineyard rows.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- This notebook contains scripts to create, train, and test a deep learning network to perform fast semantic segmentation on platform with mobile CPUs and low memory capabilities\n",
    "\n",
    "- The implemented architecture is a MobileNetV3 with a customized LR-ASSP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Required libraries\n",
    "\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "#from tqdm.notebook import tqdm as tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the working GPU\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_visible_devices(gpus[1], 'GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[1], True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DIR = 'datasets_segmentation'\n",
    "training_dataset_dir = os.path.join(PATH_DIR, 'training_dataset')\n",
    "test_dataset_dir = os.path.join(PATH_DIR, 'test_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img_list = glob.glob(os.path.join(training_dataset_dir, '*.jpg'))\n",
    "train_mask_list = glob.glob(os.path.join(training_dataset_dir, '*mask.jpg'))\n",
    "\n",
    "test_img_list = glob.glob(os.path.join(test_dataset_dir, '*.jpg'))\n",
    "test_mask_list = glob.glob(os.path.join(test_dataset_dir, '*mask.jpg'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load images and masks in two separate arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(imgList, maskList):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in tqdm(imgList):\n",
    "        for j in maskList:\n",
    "            img_name = os.path.split(i)[1].split('.jpg')[0].split('_')[1]\n",
    "            mask_name = os.path.split(j)[1].split('.jpg')[0].split('_')[1]\n",
    "\n",
    "            if img_name == mask_name:            \n",
    "                img = cv2.imread(i)\n",
    "                mask = cv2.imread(j,0)\n",
    "                X.append(img)\n",
    "                y.append(mask)\n",
    "                name_X.append(os.path.split(i)[1].split('.jpg')[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "    return (np.array(X), np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X,y are for training and validation\n",
    "X, y = loadData(train_img_list, train_mask_list)\n",
    "\n",
    "#X_test,y_test are for testing\n",
    "X_test, y_test = loadData(test_img_list, test_mask_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Shuffle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask and image must be shuffled with the same index\n",
    "def custom_shuffle(img_array, mask_array):\n",
    "    assert len(img_array) == len(mask_array)\n",
    "    p = np.random.permutation(len(img_array))\n",
    "    return img_array[p], mask_array[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=custom_shuffle(X,y)\n",
    "X_test,y_test=custom_shuffle(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0 Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = X[index]\n",
    "mask = y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the mask over the image\n",
    "plt.figure(figsize=(14,10))\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.imshow(mask, alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0 Pre-process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input shape network\n",
    "in_net_h=224\n",
    "in_net_w=224\n",
    "net_channels=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize the prediction mantaining the aspect ratio for X\n",
    "\n",
    "def resizeImage(X, width, force_dim=False, height = None):\n",
    "    X_res = []\n",
    "    for img in tqdm(X):\n",
    "        r = width / img.shape[1]\n",
    "        dim = (width, int(img.shape[0] * r))\n",
    "        # not mantain the ratio\n",
    "        if force_dim:\n",
    "            img_resized = cv2.resize(img.astype('uint8'), (width,height), interpolation = cv2.INTER_AREA)\n",
    "        else:\n",
    "            img_resized = cv2.resize(img.astype('uint8'), dim, interpolation = cv2.INTER_AREA)\n",
    "        X_res.append(img_resized)\n",
    "        \n",
    "    return np.array(X_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize the prediction mantaining the aspect ratio for y\n",
    "def resizeImage_y(y, width, force_dim=False, height = None):\n",
    "    y_res = []\n",
    "    for img,img1 in tqdm(zip(y[:,0],y[:,1])):\n",
    "        \n",
    "        \n",
    "        r = width / img.shape[1]\n",
    "        dim = (width, int(img.shape[0] * r))\n",
    "        # not mantain the ratio\n",
    "        if force_dim:\n",
    "            img_resized = cv2.resize(img.astype('uint8'), (width,height), interpolation = cv2.INTER_AREA)\n",
    "        else:\n",
    "            img_resized = cv2.resize(img.astype('uint8'), dim, interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "        r = width / img1.shape[1]\n",
    "        dim = (width, int(img1.shape[0] * r))\n",
    "        # not mantain the ratio\n",
    "        if force_dim:\n",
    "            img_resized1 = cv2.resize(img1.astype('uint8'), (width,height), interpolation = cv2.INTER_AREA)\n",
    "        else:\n",
    "            img_resized1 = cv2.resize(img1.astype('uint8'), dim, interpolation = cv2.INTER_AREA)\n",
    "            \n",
    "            \n",
    "        y_res.append([img_resized,img_resized1])\n",
    "    \n",
    "    return np.array(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X):\n",
    "    return (X / 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Resize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize the images and masks with the accepted dimensions by the network\n",
    "\n",
    "X = resizeImage(X, in_net_w, force_dim=True, height = in_net_h)\n",
    "X_test = resizeImage(X=X_test,width= in_net_w, force_dim=True, height = in_net_h)\n",
    "\n",
    "y = resizeImage(y, in_net_w, force_dim=True, height = in_net_h)\n",
    "y_test = resizeImage(X=y_test, width=in_net_w, force_dim=True, height = in_net_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Normalize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = normalize(X)\n",
    "X_test = normalize(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= normalize(y)\n",
    "y_test= normalize(X=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply a threshold to have 0,1 despite the resizing\n",
    "y[y>=(0.5)]=1.0    \n",
    "y[y<(0.5)]=0.0\n",
    "\n",
    "#Apply a threshold to have 0,1 despite the resizing\n",
    "y_test[y_test>=(0.5)]=1.0\n",
    "y_test[y_test<(0.5)]=0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0 Build and Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from datetime import datetime\n",
    "\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, Activation, Input, Add, AveragePooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Reshape,Dropout, Multiply, Flatten,UpSampling2D\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.optimizers import SGD,RMSprop,Adam\n",
    "from tensorflow.keras.utils import get_custom_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import network\n",
    "from tensorflow.keras.applications import MobileNetV3Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save checkpoints\n",
    "\n",
    "model_dir = os.path.join(PATH_DIR, 'bin')\n",
    "\n",
    "if not os.path.exists(model_dir):\n",
    "    os.mkdir(model_dir)\n",
    "    \n",
    "name = 'MobileNet_V3'\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"logs\"\n",
    "logdir = \"{}/run-{}_{}/\".format(root_logdir, now,name)\n",
    "\n",
    "backup_model_path = os.path.join(model_dir, '{}.h5'.format(name))\n",
    "backup_weights_path = os.path.join(model_dir, '{}_weights.h5'.format(name))\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=backup_weights_path, \n",
    "                               monitor = 'loss',\n",
    "                               verbose=1, \n",
    "                               save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define custom activation function\n",
    "def hard_swish(x):\n",
    "    return x * tf.nn.relu6(x + 3) / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining dropout_r\n",
    "dropout_r=0.2\n",
    "\n",
    "#Base model mobile net\n",
    "model_base= MobileNetV3Large(input_shape=(in_net_w,in_net_h,3),\n",
    "                     alpha=1.0,\n",
    "                     minimalistic=False,\n",
    "                     include_top=False,\n",
    "                     weights='imagenet',\n",
    "                     input_tensor=None,\n",
    "                     classes=1,\n",
    "                     pooling='avg',\n",
    "                     dropout_rate=dropout_r,\n",
    "                     backend=keras.backend, layers=keras.layers, models=tf.keras.models, utils=tf.keras.utils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_number=41\n",
    "\n",
    "#Adding segmentation head\n",
    "\n",
    "def buildModel(base_model, dropout_rate= dropout_r, n_class=1): \n",
    "    global activation_number\n",
    "    #1/8 resolution output\n",
    "    \n",
    "    out_1_8= base_model.get_layer('activation_15').output\n",
    "    \n",
    "    #1/16 resolution output\n",
    "    \n",
    "    out_1_16= base_model.get_layer('activation_29').output\n",
    "    \n",
    "    \n",
    "    # branch1\n",
    "    x1 = Conv2D(128, (1, 1))(out_1_16)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    \n",
    "    layer_name_act=\"activation_head\"+str(activation_number)\n",
    "    x1 = Activation('relu',name=layer_name_act)(x1)\n",
    "    activation_number+=1\n",
    "    \n",
    "    # branch2\n",
    "    s = x1.shape\n",
    "\n",
    "    #custom average pooling2D\n",
    "    x2 = AveragePooling2D(pool_size=(12, 12), strides=(4, 5),data_format='channels_last')(out_1_16)\n",
    "    x2 = Conv2D(128, (1, 1))(x2)\n",
    "    \n",
    "    \n",
    "    layer_name_act=\"activation_head\"+str(activation_number)\n",
    "    \n",
    "    x2 = Activation('sigmoid',name=layer_name_act)(x2)\n",
    "    activation_number+=1\n",
    "    \n",
    "\n",
    "    x2 = UpSampling2D(size=(int(s[1]), int(s[2])),data_format='channels_last',interpolation=\"bilinear\")(x2)\n",
    "\n",
    "    \n",
    "    \n",
    "    # branch3\n",
    "    x3 = Conv2D(n_class, (1, 1))(out_1_8)\n",
    "    \n",
    "    # multiply\n",
    "    m1 = Multiply()([x1, x2])\n",
    "\n",
    "    m1 = UpSampling2D(size=(2, 2),data_format='channels_last',interpolation=\"bilinear\")(m1)\n",
    "    m1 = Conv2D(n_class, (1, 1))(m1)\n",
    "\n",
    "    # add\n",
    "    m2 = Add()([m1, x3])\n",
    "\n",
    "    \n",
    "    #adding this UPsampling of factor 8\n",
    "    m2 = UpSampling2D(size=(8, 8),data_format='channels_last',interpolation=\"bilinear\")(m2)\n",
    "\n",
    "    \n",
    "    # predictions \n",
    "    layer_name_act=\"activation_head\"+str(activation_number)\n",
    "    predictions = Activation('sigmoid',name=layer_name_act)(m2)\n",
    "    \n",
    "    \n",
    "    activation_number+=1 \n",
    "\n",
    "\n",
    "    # final model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=buildModel(base_model=model_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the optimizers\n",
    "optimizer_r = RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "optimizer_a = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=True)\n",
    "optimizer_SDG=SGD(learning_rate=0.01, momentum=0.0, nesterov=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_IoU(y_true, y_pred): \n",
    "    \n",
    "    intersection_tensor=tf.math.multiply(y_true,y_pred)\n",
    "    inter=tf.reduce_sum(intersection_tensor)\n",
    "    \n",
    "    union=tf.reduce_sum(tf.math.subtract(tf.math.add(y_true,y_pred),intersection_tensor))\n",
    "    \n",
    "    \n",
    "    iou= tf.math.divide(inter,union)\n",
    "    return 1-iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric\n",
    "def class_IoU(y_true, y_pred):\n",
    "\n",
    "    \n",
    "    threshold = tf.constant([0.9])\n",
    "    y_pred_threshold=tf.cast(tf.math.greater(y_pred, threshold),tf.int32)\n",
    "    y_true=tf.cast(y_true,tf.int32)\n",
    "    \n",
    "\n",
    "    intersection_tensor=tf.math.multiply(y_true,y_pred_threshold)\n",
    "    inter=tf.reduce_sum(intersection_tensor)\n",
    "    \n",
    "    #union= a+b-intersection\n",
    "    union=tf.reduce_sum(tf.math.subtract(tf.math.add(y_true,y_pred_threshold),intersection_tensor))\n",
    "    \n",
    "    \n",
    "    return tf.math.divide(inter,union)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Transfer learning: freeze the lower layers\n",
    "\n",
    "\n",
    "Freezing the lower layers for a few epochs and then train the whole model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the model \n",
    "model.compile(optimizer=optimizer_r, loss=loss_IoU, metrics = [class_IoU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The first layers have been already frozen previously\n",
    "\n",
    "early_stopping_ = tf.keras.callbacks.EarlyStopping(patience=3)\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "# Train the model on the new data for a few epochs\n",
    "history_F = model.fit(x = X, y = y,\n",
    "                    batch_size = 32,\n",
    "                    epochs = n_epochs,\n",
    "                    validation_split = 0.1, \n",
    "                    shuffle = True,\n",
    "                    callbacks = [early_stopping_]\n",
    "                     )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0 Test the Model\n",
    "\n",
    "\n",
    "Test the model in different vineyard parcels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0 Compute metrics for paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Pixel accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc_list=[]\n",
    "for jj in tqdm(range(len(X_test))):\n",
    "    y_pred = model.predict(X_test[jj][None,...])\n",
    "    y_pred = (y_pred[0,:,:,0] > 0.9)\n",
    "    temp=np.equal(y_pred,y_test[jj])\n",
    "    score=np.sum(temp)\n",
    "    accuracy=score/(224**2)\n",
    "    acc_list.append(accuracy)\n",
    "\n",
    "acc_nump=np.array(acc_list)\n",
    "np.mean(acc_nump)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Precision @ different thresholds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_list=[]\n",
    "for jj in tqdm(range(len(X_test))):\n",
    "    y_pred = model.predict(X_test[jj][None,...])\n",
    "    iou=class_IoU(y_test[jj], y_pred[0,:,:,0])\n",
    "    iou_list.append(iou.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_list=np.array(iou_list)\n",
    "print(\"iou greater 0.4 and %\")\n",
    "a1=len(np.where(iou_list>0.4)[0])\n",
    "print(a1,a1/500)\n",
    "print(\"iou greater 0.5 and %\")\n",
    "a1=len(np.where(iou_list>0.5)[0])\n",
    "print(a1,a1/500)\n",
    "print(\"iou greater 0.6 and %\")\n",
    "a1=len(np.where(iou_list>0.6)[0])\n",
    "print(a1,a1/500)\n",
    "print(\"iou greater 0.7 and %\")\n",
    "a1=len(np.where(iou_list>0.7)[0])\n",
    "print(a1,a1/500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "cwd = os.getcwd()\n",
    "model_path = os.path.join(cwd,'bin','mobileNetv3_segmentation_new1.h5')\n",
    "model.save(model_path, save_format='h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.0 Test on a random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "model_path = os.path.join(cwd,'bin','mobileNetv3_segmentation_new1.h5')\n",
    "model=tf.keras.models.load_model(model_path,\n",
    "                                 custom_objects={\"hard_swish\": hard_swish,\"loss_IoU\": loss_IoU,\"class_IoU\":class_IoU}\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_new = cv2.imread('frame_5260.jpg') \n",
    "\n",
    "x_test_new = cv2.cvtColor(x_test_new, cv2.COLOR_BGR2RGB)\n",
    "x_test_new = cv2.resize(x_test_new.astype('uint8')\n",
    "                        , (224,224), interpolation = cv2.INTER_AREA)\n",
    "x_test_new = normalize(x_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPrediction(x, y_pred):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15,15))\n",
    "    axes[0].imshow(x)\n",
    "    axes[1].imshow(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test_new[None,...])\n",
    "y_pred = (y_pred > 0.9)\n",
    "plotPrediction(x_test_new, y_pred[0,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.0 Vegetation index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datasets_segmentation/training_dataset\n",
    "img_test = cv2.imread('vegetation_index/frame_5260.jpg')\n",
    "img_test = cv2.cvtColor(img_test, cv2.COLOR_BGR2RGB)\n",
    "img_test = cv2.resize(img_test.astype('uint8'), (224,224), interpolation = cv2.INTER_AREA)\n",
    "img_test = normalize(img_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test_new[None,...])\n",
    "y_pred = (y_pred > 0.9)\n",
    "plotPrediction(x_test_new, y_pred[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('vegetation_index/frame_11115.jpg')\n",
    "\n",
    "x_test_new = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "x_test_new = cv2.resize(x_test_new.astype('uint8'), (224,224), interpolation = cv2.INTER_AREA)\n",
    "x_test_new = normalize(x_test_new)\n",
    "img = cv2.resize(img.astype('uint8'), (224,224), interpolation = cv2.INTER_AREA)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "y_pred = model.predict(x_test_new[None,...])\n",
    "y_pred = (y_pred > 0.9)\n",
    "\n",
    "#Show the mask over the image\n",
    "plt.figure(figsize=(8,8),frameon=False)\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "\n",
    "#Remove pink from sky\n",
    "rem_pred=y_pred[0,:,:,0].astype(np.float)\n",
    "\n",
    "rem_pred[rem_pred==0]=np.NaN\n",
    "plt.imshow(rem_pred, alpha=0.4,cmap='Spectral')\n",
    "\n",
    "plt.savefig('s_veg2.png', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reverse colours\n",
    "gira=cv2.imread('s_veg2.png')\n",
    "gira=cv2.cvtColor(gira, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(8,8),frameon=False)\n",
    "plt.axis('off')\n",
    "plt.imshow(gira)\n",
    "plt.savefig('s_veg2.png', bbox_inches='tight', pad_inches=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output=y_pred[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute vegetation index\n",
    "veg=np.zeros((224,224))\n",
    "\n",
    "for x,y in zip(np.where(output)[0],np.where(output)[1]):\n",
    "    veg[x,y]=(img[x,y,1]-img[x,y,0])/(img[x,y,1]+img[x,y,0]-img[x,y,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove outliers \n",
    "veg[veg>1]=np.NaN \n",
    "veg[veg==0]=np.NaN\n",
    "veg[veg==np.inf]=np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Normalize\n",
    "min_max_scaler = MinMaxScaler()\n",
    "map_veg = min_max_scaler.fit_transform(veg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.axis('off')\n",
    "\n",
    "cf=plt.imshow(map_veg,cmap='inferno')\n",
    "cd= plt.colorbar(cf)\n",
    "\n",
    "cd.set_ticklabels(['LOW','HIGH'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow2.4",
   "language": "python",
   "name": "tensorflow2.4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
